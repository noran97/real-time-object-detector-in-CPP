# YOLO Inference in C++

This project provides a simple **C++ implementation of YOLOv7 inference** using [ONNX Runtime](https://onnxruntime.ai/).  
It allows you to run **object detection** on images and videos efficiently, with optional **CUDA acceleration** for faster performance.

---

## ðŸš€ Features

- ðŸ“¦ Load YOLOv7 ONNX models with **ONNX Runtime**  
- ðŸ–¼ï¸ Run inference on **images and videos**  
- ðŸ“Š Display results with **bounding boxes, class names, and confidence scores**  
- âš¡ Support for both **CPU** and **CUDA (GPU)** execution  
- ðŸ§© **Modular structure**: code separated into `Detector.h`, `Detector.cpp`, and `main.cpp`  

---
## ðŸ”§ Requirements

- C++17 or later  
- CMake (>= 3.12)  
- OpenCV (>= 4.0)  
- ONNX Runtime (with CUDA support if using GPU)  


